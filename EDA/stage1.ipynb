{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "bool_tensor = torch.tensor([True, True, False])\n",
    "\n",
    "# Option 1: Using torch.nonzero\n",
    "int_indices = torch.nonzero(bool_tensor).squeeze()\n",
    "\n",
    "\n",
    "print(int_indices)  # output: tensor([0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/wlsgur4011/part_assembly/src/pointnext\n"
     ]
    }
   ],
   "source": [
    "cd /data/wlsgur4011/part_assembly/src/pointnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "from jhutil import show_point_clouds\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-07-14 15:56:16]\u001b[0m \u001b[1;30m[DEBU]\u001b[0m \u001b[32mPopen(['git', 'version'], cwd=/data/wlsgur4011/part_assembly/src/pointnext, universal_newlines=False, shell=None, istream=None)\u001b[0m\n",
      "\u001b[32m[2023-07-14 15:56:16]\u001b[0m \u001b[1;30m[DEBU]\u001b[0m \u001b[32mPopen(['git', 'version'], cwd=/data/wlsgur4011/part_assembly/src/pointnext, universal_newlines=False, shell=None, istream=None)\u001b[0m\n",
      "\u001b[32m[2023-07-14 15:56:16]\u001b[0m \u001b[1;30m[DEBU]\u001b[0m \u001b[32mTrying paths: ['/root/.docker/config.json', '/root/.dockercfg']\u001b[0m\n",
      "\u001b[32m[2023-07-14 15:56:16]\u001b[0m \u001b[1;30m[DEBU]\u001b[0m \u001b[32mNo config file found\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shortuuid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m warnings\u001b[39m.\u001b[39msimplefilter(action\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mFutureWarning\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m/data/wlsgur4011/part_assembly/src/pointnext/examples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenpoints\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m build_model_from_cfg\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenpoints\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m torch_grouping_operation, knn_point\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenpoints\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloss\u001b[39;00m \u001b[39mimport\u001b[39;00m build_criterion_from_cfg\n",
      "File \u001b[0;32m/data/wlsgur4011/part_assembly/src/pointnext/openpoints/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/data/wlsgur4011/part_assembly/src/pointnext/openpoints/transforms/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mAuthor: PointNeXt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtransforms_factory\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m \n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpoint_transformer_gpu\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpoint_transform_cpu\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/data/wlsgur4011/part_assembly/src/pointnext/openpoints/transforms/transforms_factory.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistry\u001b[39;00m \u001b[39mimport\u001b[39;00m Registry\n\u001b[1;32m      4\u001b[0m DataTransforms \u001b[39m=\u001b[39m Registry(\u001b[39m'\u001b[39m\u001b[39mdatatransforms\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat_collate_fn\u001b[39m(datas):\n",
      "File \u001b[0;32m/data/wlsgur4011/part_assembly/src/pointnext/openpoints/utils/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrandom\u001b[39;00m \u001b[39mimport\u001b[39;00m set_random_seed\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m EasyConfig, print_args\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlogger\u001b[39;00m \u001b[39mimport\u001b[39;00m setup_logger_dist, generate_exp_directory, resume_exp_directory\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwandb\u001b[39;00m \u001b[39mimport\u001b[39;00m Wandb\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m AverageMeter, ConfusionMatrix, get_mious\n",
      "File \u001b[0;32m/data/wlsgur4011/part_assembly/src/pointnext/openpoints/utils/logger.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtermcolor\u001b[39;00m \u001b[39mimport\u001b[39;00m colored\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mshortuuid\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpathlib\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mshutil\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shortuuid'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import distributed as dist, multiprocessing as mp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_scatter import scatter\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "sys.path.insert(0, \"/data/wlsgur4011/part_assembly/src/pointnext/examples\")\n",
    "\n",
    "from openpoints.models import build_model_from_cfg\n",
    "from openpoints.models.layers import torch_grouping_operation, knn_point\n",
    "from openpoints.loss import build_criterion_from_cfg\n",
    "from openpoints.scheduler import build_scheduler_from_cfg\n",
    "from openpoints.optim import build_optimizer_from_cfg\n",
    "from openpoints.dataset import build_dataloader_from_cfg, get_class_weights, get_features_by_keys\n",
    "from openpoints.transforms import build_transforms_from_cfg\n",
    "from openpoints.utils import AverageMeter, ConfusionMatrix\n",
    "from openpoints.utils import set_random_seed, save_checkpoint, load_checkpoint, resume_checkpoint, setup_logger_dist, \\\n",
    "    cal_model_parm_nums, Wandb, generate_exp_directory, resume_exp_directory, EasyConfig, dist_utils, find_free_port\n",
    "from openpoints.models.layers import furthest_point_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = [\"examples/segmentation/main.py\" ,\"--cfg\" ,\"cfgs/part_assembly/pointnext-l.yaml\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "launch mp with 1 GPUs, current rank: 0\n"
     ]
    }
   ],
   "source": [
    "def get_config():\n",
    "    parser = argparse.ArgumentParser('Scene segmentation training/testing')\n",
    "    parser.add_argument('--cfg', type=str, required=True, help='config file')\n",
    "    parser.add_argument('--profile', action='store_true', default=False, help='set to True to profile speed')\n",
    "    args, opts = parser.parse_known_args()\n",
    "    cfg = EasyConfig()\n",
    "    cfg.load(args.cfg, recursive=True)\n",
    "    cfg.update(opts)  # overwrite the default arguments in yml\n",
    "    \n",
    "    if cfg.seed is None:\n",
    "        cfg.seed = np.random.randint(1, 10000)\n",
    "    \n",
    "    # init distributed env first, since logger depends on the dist info.\n",
    "    cfg.rank, cfg.world_size, cfg.distributed, cfg.mp = dist_utils.get_dist_info(cfg)\n",
    "    cfg.sync_bn = cfg.world_size > 1\n",
    "    \n",
    "    # init log dir\n",
    "    cfg.task_name = args.cfg.split('.')[-2].split('/')[-2]  # task/dataset name, \\eg s3dis, modelnet40_cls\n",
    "    cfg.cfg_basename = args.cfg.split('.')[-2].split('/')[-1]  # cfg_basename, \\eg pointnext-xl\n",
    "    tags = [\n",
    "        cfg.task_name,  # task name (the folder of name under ./cfgs\n",
    "        cfg.mode,\n",
    "        cfg.cfg_basename,  # cfg file name\n",
    "        f'ngpus{cfg.world_size}',\n",
    "        f'seed{cfg.seed}',\n",
    "    ]\n",
    "    opt_list = []  # for checking experiment configs from logging file\n",
    "    for i, opt in enumerate(opts):\n",
    "        if 'rank' not in opt and 'dir' not in opt and 'root' not in opt and 'pretrain' not in opt and 'path' not in opt and 'wandb' not in opt and '/' not in opt:\n",
    "            opt_list.append(opt)\n",
    "    cfg.root_dir = os.path.join(cfg.root_dir, cfg.task_name)\n",
    "    cfg.opts = '-'.join(opt_list)\n",
    "    \n",
    "    cfg.is_training = cfg.mode not in ['test', 'testing', 'val', 'eval', 'evaluation']\n",
    "    if cfg.mode in ['resume', 'val', 'test']:\n",
    "        resume_exp_directory(cfg, pretrained_path=cfg.pretrained_path)\n",
    "        cfg.wandb.tags = [cfg.mode]\n",
    "    else:\n",
    "        generate_exp_directory(cfg, tags, additional_id=os.environ.get('MASTER_PORT', None))\n",
    "        cfg.wandb.tags = tags\n",
    "    os.environ[\"JOB_LOG_DIR\"] = cfg.log_dir\n",
    "    cfg_path = os.path.join(cfg.run_dir, \"cfg.yaml\")\n",
    "    with open(cfg_path, 'w') as f:\n",
    "        yaml.dump(cfg, f, indent=2)\n",
    "        os.system('cp %s %s' % (args.cfg, cfg.run_dir))\n",
    "    cfg.cfg_path = cfg_path\n",
    "    \n",
    "    # wandb config\n",
    "    cfg.wandb.name = cfg.run_name\n",
    "    \n",
    "    if cfg.model.get('in_channels', None) is None:\n",
    "        cfg.model.in_channels = cfg.model.encoder_args.in_channels\n",
    "        \n",
    "    return cfg\n",
    "\n",
    "cfg = get_config()\n",
    "set_random_seed(cfg.seed + cfg.rank, deterministic=cfg.deterministic)\n",
    "torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model & data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-06-01 15:48:36]\u001b[0m \u001b[1;30m[INFO]\u001b[0m \n",
      "Totally 17686 samples in val set\n"
     ]
    }
   ],
   "source": [
    "val_loader = build_dataloader_from_cfg(cfg.get('val_batch_size', cfg.batch_size),\n",
    "                                       cfg.dataset,\n",
    "                                       cfg.dataloader,\n",
    "                                       datatransforms_cfg=cfg.datatransforms,\n",
    "                                       split='val',\n",
    "                                       distributed=cfg.distributed\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in val_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41m1111  {\n",
      "    \"pos\": \"tensor[1, 29751, 3] n=89253 (0.3Mb) x∈[-1.912, 5.608] μ=0.942 σ=1.797\",\n",
      "    \"x\": \"tensor[1, 29751, 3] n=89253 (0.3Mb) x∈[-8.267, 2.856] μ=-2.607 σ=3.111\",\n",
      "    \"y\": \"tensor[1, 29751] i64 0.2Mb x∈[0, 1] μ=0.137 σ=0.344\",\n",
      "    \"heights\": \"tensor[1, 29751, 1] 0.1Mb x∈[0., 5.608] μ=2.827 σ=1.612\"\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import jhutil; jhutil.jhprint(1111, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jhutil import show_point_clouds\n",
    "\n",
    "pos = data[\"pos\"][0]\n",
    "y = data[\"y\"][0]\n",
    "\n",
    "show_point_clouds([pos[y == 0], pos[y == 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
